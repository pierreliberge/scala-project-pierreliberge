package fr.mosef.scala.template

import fr.mosef.scala.template.processor.impl.ProcessorImpl
import fr.mosef.scala.template.reader.impl.ReaderImpl
import org.apache.spark.sql.{DataFrame, SparkSession}

object Main {

  def main(args: Array[String]): Unit = {
    if (args.length < 1) {
      println("âŒ Veuillez fournir le chemin du fichier en argument.")
      System.exit(1)
    }

    val srcPath = args(0)
    val sparkSession = SparkSession.builder()
      .appName("Projet Spark - Traitement de donnÃ©es")
      .master("local[*]")
      .getOrCreate()

    val reader = new ReaderImpl(sparkSession)
    val processor = new ProcessorImpl()

    // Lecture intelligente du fichier (CSV ou Parquet)
    val df: DataFrame = if (srcPath.toLowerCase.endsWith(".parquet")) {
      println("ðŸ“¦ Lecture du fichier Parquet...")
      reader.readParquet(srcPath)
    } else {
      println("ðŸ“„ Lecture du fichier CSV...")
      reader.readCSV(srcPath)
    }

    // Affichage du schÃ©ma pour debug
    println("ðŸ“Œ SchÃ©ma du DataFrame chargÃ© :")
    df.printSchema()
    println("ðŸ§± Colonnes dÃ©tectÃ©es : " + df.columns.mkString(", "))

    // === Traitements ===
    val rapportClasse = processor.rapportParClasseDePassager(df)
    val rapportSexeClasse = processor.rapportParSexeEtClasse(df)
    val passagersSansEmbarquement = processor.rapportPassagersSansEmbarquement(df)

    // === Affichage des rÃ©sultats ===
    println("\nðŸ“Š Rapport par classe de passager :")
    rapportClasse.show()

    println("\nðŸ“Š Rapport par sexe et classe :")
    rapportSexeClasse.show()

    println("\nðŸ•µï¸ Passagers sans information d'embarquement :")
    passagersSansEmbarquement.show()

    sparkSession.stop()
  }
}
